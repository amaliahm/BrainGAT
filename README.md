# ðŸ§  BrainGAT

Graph Attention Network Approach for Multi-Class Brain Tumor Classification, a research project exploring the use of Graph Attention Networks (GATs) for multi-class brain tumor classification using MRI images. It is based on the paper *â€œMulti-class Brain Tumor Segmentation using Graph Attention Networkâ€* and leverages the Brain Tumor MRI Dataset from Kaggle.

---

### ðŸ“š Table of Contents

```
- Overview
- Dataset
- Methodology
- Model Architecture
- Training Process
- Results
- How to Run
- References
```

### ðŸ§© Overview

> Brain tumor classification is a critical task in medical image analysis. Traditional CNNs fail to capture long-range spatial dependencies. This project investigates how Graph Attention Networks (GATs) can represent pixel/region relationships as a graph to enhance segmentation performance.

---

### ðŸ“Š Dataset 

**Dataset:** [Brain Tumor MRI Dataset (Kaggle)](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset).

It's a combination of those three datasets: figshare, SARTAJ dataset and Br35H.

Contains MRI scans categorized into 4 classes: glioma, meningioma, pituitary tumor, and healthy brain.

Preprocessing steps: resizing, normalization, graph construction from pixel regions or superpixels.

---

### âš™ï¸ Methodology
* Preprocess MRI scans into graph structures (nodes = regions, edges = spatial proximity).
* Use Graph Attention Networks (GAT) for feature propagation.
* Apply Softmax for multi-class classification output.
* Evaluation.
---

### ðŸ§  Model Architecture
```
Input: Graph with 80 nodes Ã— 25 features
   â†“
[GAT Layer 1] - Multi-head attention (6 heads)
   â€¢ Learns which neighboring regions are important
   â€¢ Output: 80 nodes Ã— (128 Ã— 6) = 768 features
   â†“
[Batch Norm + ELU + Dropout]
   â†“
[GAT Layer 2] - Multi-head attention (6 heads)
   â€¢ Refines attention patterns
   â€¢ Output: 80 nodes Ã— 768 features
   â†“
[GAT Layer 3] - Single-head attention
   â€¢ Final attention refinement
   â€¢ Output: 80 nodes Ã— 128 features
   â†“
[Global Pooling] - Aggregate nodes to graph level
   â€¢ Mean pooling: average all 80 nodes â†’ 128 features
   â€¢ Max pooling: max across all 80 nodes â†’ 128 features
   â€¢ Concatenate: 256 features
   â†“
[Classification Head] - FC layers
   â€¢ FC1: 256 â†’ 128
   â€¢ FC2: 128 â†’ 4 (final classes)
   â†“
Output: [Glioma, Meningioma, No Tumor, Pituitary]
```
---

### ðŸ’» Training Process
* For each epoch:

```
Forward Pass:
   Batch of graphs â†’ GAT â†’ Predictions
Loss Calculation:
   Predicted class vs True class â†’ NLL Loss
Backward Pass:
   Compute gradients â†’ Clip gradients â†’ Update weights
Validation:
   Evaluate on validation set â†’ Check accuracy
Early Stopping:
   - If validation accuracy doesn't improve for 15 epochs â†’ Stop
   - Save best model when validation accuracy improves
```
---

### ðŸ“ˆ Results
- **Test Accuracy**: 96.43%
- **Best classes**: No Tumor, Pituitary (easier to distinguish)
- **Challenging**: Glioma vs Meningioma (similar patterns)
---

### ðŸ”¬ References

> * Original paper: *â€œMulti-class Brain Tumor Segmentation using Graph Attention Networkâ€*
> * Dataset: *Brain MRI Images Dataset â€“ Kaggle*
> * Framework: *PyTorch Geometric Documentation*